{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b668a83f-b360-4de5-a448-98752c5293b9",
   "metadata": {},
   "source": [
    "# Local Mode End-to-End Forecasting Pipeline\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb3baf5-8f71-4a98-af8a-ab2ff615297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Date & Time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Math\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "from matplotlib import gridspec as gs\n",
    "\n",
    "# Statistical Models\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, median_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# HyperOpt\n",
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
    "from hyperopt.pyll import scope as ho_scope\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample\n",
    "\n",
    "# OS & Functional Tools \n",
    "import copy\n",
    "from os import devnull\n",
    "from functools import partial\n",
    "from contextlib import contextmanager, redirect_stdout, redirect_stderr\n",
    "\n",
    "# Notebook Optimization\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec032fed-6fc2-4207-be2c-b96dd54c0401",
   "metadata": {},
   "source": [
    "#### Setting Context Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b440703-bee0-4884-8660-c81ea69db1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def suppress_annoying_prints():\n",
    "    with open(devnull, 'w') as black_hole:\n",
    "        with redirect_stdout(black_hole) as chatter, redirect_stderr(black_hole) as noisy_errors:\n",
    "            yield (chatter, noisy_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8480cbe-5348-4954-8eb3-8bb319ab1a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/isisromero/desktop/MLEIA/chap_07/air-passenger-traffic-per-month-port-authority-of-ny-nj-beginning-1977.csv'\n",
    "AIRPORT_FIELD = 'Airport Code'\n",
    "SERIES_FREQ = 'MS'\n",
    "TID_COL = 'TestID'\n",
    "BIG_FONT = 22\n",
    "MED_FONT = 16\n",
    "SMALL_FONT = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4b789-485b-4e4b-9355-911d1e061e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ac4dde1-f38e-40fb-b615-e5a58da438d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_index_freq(data, freq):\n",
    "    return data.asfreq(freq)\n",
    "\n",
    "def pull_raw_airport_data(file_location):\n",
    "    raw = pd.read_csv(file_location)\n",
    "    raw = raw.copy(deep=False)\n",
    "    raw['Month'] = pd.to_datetime(raw['Month'], format='%b').dt.month\n",
    "    raw.loc[:, 'Day'] = 1\n",
    "    raw['date'] = pd.to_datetime(raw[['Year', 'Month', 'Day']])\n",
    "    raw.set_index('date', inplace=True)\n",
    "    raw.index = pd.DatetimeIndex(raw.index.values, freq=raw.index.inferred_freq)\n",
    "    asc = raw.sort_index()\n",
    "    return asc\n",
    "\n",
    "\n",
    "def get_airport_data_from_df(full_file, freq, airport):\n",
    "    filtered = full_file[full_file[AIRPORT_FIELD] == airport]\n",
    "    return apply_index_freq(filtered, freq)\n",
    "\n",
    "def get_airport_data(file_location, freq, airport):\n",
    "    all_data = pull_raw_airport_data(file_location)\n",
    "    return partial(get_airport_data_from_df, all_data, freq)(airport)\n",
    "\n",
    "def get_all_airports_from_df(full_file):\n",
    "    return sorted(full_file[AIRPORT_FIELD].unique())\n",
    "\n",
    "def generate_splits_by_months(data, months):\n",
    "    train = data[:-months].ffill().bfill()\n",
    "    test = data[-months:].ffill().bfill()\n",
    "    return train, test\n",
    "\n",
    "def validate_data_counts(data, split_count):\n",
    "    return split_count / 0.2 < len(data) * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a893ab9d-5c95-4e55-8956-f6f662f12a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    drop_case = y_true != 0\n",
    "    return (np.fabs(y_true - y_pred) / y_true)[drop_case].mean() * 100\n",
    "\n",
    "def aic(n, mse, param_count):\n",
    "    return n * np.log(mse) + 2 * param_count\n",
    "\n",
    "def bic(n, mse, param_count):\n",
    "    return n * np.log(mse) + param_count * np.log(n)\n",
    "\n",
    "def calculate_errors(y_true, y_pred, param_count):\n",
    "    error_scores = {}\n",
    "    pred_length = len(y_pred)\n",
    "    try: \n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        mse = 1e12\n",
    "    try:\n",
    "        error_scores['mae'] = mean_absolute_error(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        error_scores['mae'] = 1e12\n",
    "    try:\n",
    "        error_scores['medae'] = median_absolute_error(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        error_scores['medae'] = 1e12\n",
    "    error_scores['mape'] = mape(y_true, y_pred)\n",
    "    error_scores['mse'] = mse\n",
    "    error_scores['rmse'] = sqrt(mse)\n",
    "    error_scores['aic'] = aic(pred_length, mse, param_count)\n",
    "    error_scores['bic'] = bic(pred_length, mse, param_count)\n",
    "    try:\n",
    "        error_scores['explained_var'] = explained_variance_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        error_scores['explained_var'] = -1e4\n",
    "    try:\n",
    "        error_scores['r2'] = r2_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        error_scores['r2'] = -1e4\n",
    "        \n",
    "    return error_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85f3ab6e-8cd7-4ef1-a8e4-e1af4bc7ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_param_count_hwes(config):\n",
    "    return len(config['model'].keys()) + len(config['fit'].keys())\n",
    "\n",
    "def extract_individual_trial_params(hpopt_config, run):\n",
    "    return space_eval(hpopt_config, {k:v[0] for (k, v) in run['misc']['vals'].items() if v})\n",
    "\n",
    "def extract_metric(run, metric_name):\n",
    "    test_ids = [x['tid'] + 1 for x in run]\n",
    "    test_metric = [x['result']['loss'] for x in run]\n",
    "    return pd.DataFrame(list(zip(test_ids, test_metric)), columns=[TID_COL, metric_name])\n",
    "\n",
    "def collapse_dict(trial_params):\n",
    "    values = {}\n",
    "    for (k, v) in trial_params.items():\n",
    "        if isinstance(v, dict):\n",
    "            values = {**values, **collapse_dict(v)}\n",
    "        else:\n",
    "            values[k] = v\n",
    "    return values\n",
    "\n",
    "def extract_hyperopt_trials(trials_run, trials_configuration, metric_name):\n",
    "    extracted_params = [collapse_dict(extract_individual_trial_params(trials_configuration, x)\n",
    "                                     ) for x in trials_run.trials]\n",
    "    params_df = pd.DataFrame(extracted_params)\n",
    "    params_df[TID_COL] = [x['tid'] + 1 for x in trials_run]\n",
    "    return extract_metric(trials_run, metric_name).merge(params_df, on=TID_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54f70ef2-5c56-4253-b6e6-655b27535578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_true, y_pred, param_count, time_series_name, value_name, \n",
    "                     image_name, style='seaborn', plot_size=(16, 12)):\n",
    "    validation_output = {}\n",
    "    error_values = calculate_errors(y_true, y_pred, param_count)\n",
    "    validation_output['errors'] = error_values\n",
    "    text_str = '\\n'.join((\n",
    "        'mae = {:.3f}'.format(error_values['mae']),\n",
    "        'medae = {:.3f}'.format(error_values['medae']),\n",
    "        'mape = {:.3f}'.format(error_values['mape']),\n",
    "        'aic = {:.3f}'.format(error_values['aic']),\n",
    "        'bic = {:.3f}'.format(error_values['bic']),\n",
    "        'mse = {:.3f}'.format(error_values['mse']),\n",
    "        'rmse = {:.3f}'.format(error_values['rmse']),\n",
    "        'explained var = {:.3f}'.format(error_values['explained_var']),\n",
    "        'r squared = {:.3f}'.format(error_values['r2']),\n",
    "    ))\n",
    "    with plt.style.context(style=style):\n",
    "        fig, axes = plt.subplots(1, 1, figsize=plot_size)\n",
    "        axes.plot(y_true, 'b-o', label='Test data for {}'.format(time_series_name))\n",
    "        axes.plot(y_pred, 'r-o', label='Forecast data for {}'.format(time_series_name))\n",
    "        axes.legend(loc='upper left', fontsize=MED_FONT)\n",
    "        axes.set_title('Raw and Predicted data trend for {}'.format(time_series_name))\n",
    "        axes.set_ylabel(value_name)\n",
    "        axes.set_xlabel(y_true.index.name)\n",
    "        for i in (axes.get_xticklabels() + axes.get_yticklabels()):\n",
    "            i.set_fontsize(SMALL_FONT)  \n",
    "        for i in [axes.title, axes.xaxis.label, axes.yaxis.label]:\n",
    "            i.set_fontsize(BIG_FONT)\n",
    "        props = dict(boxstyle='round', facecolor='oldlace', alpha=0.5)\n",
    "        axes.text(0.05, 0.9, text_str, transform=axes.transAxes, fontsize=MED_FONT, \n",
    "                  verticalalignment='top', bbox=props)\n",
    "        validation_output['plot'] = fig\n",
    "        plt.savefig(image_name, format='svg')\n",
    "        plt.tight_layout()\n",
    "    return validation_output\n",
    "\n",
    "\n",
    "def annotate_num(x, y, z, metric, param, ax):\n",
    "    xmax = x[np.argmin(y)]\n",
    "    ymax = y.min()\n",
    "    zmax = z[np.argmin(y)]\n",
    "    text_value = \"Best Model\\n{}={:.4f} \\niteration={} \\n{}={:.3f}\".format(param, xmax, zmax, metric, ymax)\n",
    "    bbox_config = dict(boxstyle='round,pad=0.5', fc='ivory', ec='grey', lw=0.8)\n",
    "    arrow = dict(facecolor='darkblue', shrink=0.01, connectionstyle='angle3,angleA=90,angleB=45')\n",
    "    conf = dict(xycoords='data',textcoords='axes fraction',arrowprops=arrow,\n",
    "                bbox=bbox_config,ha='left', va='center', fontsize=MED_FONT)\n",
    "    ax.annotate(text_value, xy=(xmax,ymax), xytext=(0.3,0.8), **conf)\n",
    "    \n",
    "def annotate_str(x, y, data, metric, param, ax):\n",
    "    xmax = x[np.argmin(y)]\n",
    "    ymax = y.min()\n",
    "    text_value = \"Best Model\\n{}={} \\niteration={} \\n{}={:.3f}\".format(\n",
    "        param, data[param].values[0], data[TID_COL].values[0], metric, ymax)\n",
    "    bbox_config = dict(boxstyle='round,pad=0.5', fc='ivory', ec='grey', lw=0.8)\n",
    "    arrow = dict(facecolor='darkblue', shrink=0.01, connectionstyle='angle3,angleA=90,angleB=45')\n",
    "    conf = dict(xycoords='data',textcoords='axes fraction',arrowprops=arrow,\n",
    "                bbox=bbox_config,ha='left', va='center', fontsize=MED_FONT)\n",
    "    ax.annotate(text_value, xy=(xmax,ymax), xytext=(0.3,0.8), **conf)\n",
    "\n",
    "def generate_hyperopt_report(hpopt_df, metric, plot_name, image_name, fig_size=(16, 36)):\n",
    "    params = [x for x in list(hpopt_df) if x not in [TID_COL, metric]]\n",
    "    COLS = 2\n",
    "    ROWS = int(math.ceil(len(params)/COLS))\n",
    "    with plt.style.context(style='seaborn'):\n",
    "        u_filter = hpopt_df[metric].quantile(0.9)\n",
    "        grid = gs.GridSpec(ROWS, COLS)\n",
    "        fig = plt.figure(figsize=fig_size)\n",
    "        for i in range(len(params)):\n",
    "            column = params[i]\n",
    "            unique_vals = sorted(hpopt_df[column].unique())\n",
    "            ax = fig.add_subplot(grid[i])\n",
    "            if len(unique_vals) > 6:\n",
    "                x = hpopt_df[column]\n",
    "                y = hpopt_df[metric]\n",
    "                im = ax.scatter(x=x, y=y, c=hpopt_df[TID_COL], marker='o', s=80, cmap=plt.cm.coolwarm, alpha=0.6)\n",
    "                fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "                annotate_num(x, y, hpopt_df[TID_COL], metric, column, ax)\n",
    "            else:\n",
    "                j = 0\n",
    "                min_metric_row = hpopt_df[hpopt_df[metric] == hpopt_df[metric].min()]\n",
    "                for i in unique_vals:\n",
    "                    y_interim = hpopt_df[hpopt_df[column] == i]\n",
    "                    y_pre_filter = y_interim[(y_interim[metric] < u_filter)]\n",
    "                    y = y_pre_filter[metric]\n",
    "                    ax.boxplot(y, positions=[j+1], widths=0.4)\n",
    "                    if isinstance(i, str): \n",
    "                        x = np.random.normal(1+j, 0.05, size=len(y))\n",
    "                    else:\n",
    "                        x = np.random.normal(1+i, 0.05, size=len(y))\n",
    "                    sp = ax.scatter(x=x, y=y, c=y_pre_filter[TID_COL], marker='o', alpha=0.6, s=80, \n",
    "                                    cmap=plt.cm.coolwarm)\n",
    "                    if min_metric_row[metric].values[0] in y_pre_filter[metric].values:\n",
    "                        annotate_str(x, y, min_metric_row, metric, column, ax)\n",
    "                    j+=1\n",
    "                fig.colorbar(sp, ax=ax, orientation='vertical')\n",
    "                ax.set_xticklabels(unique_vals)\n",
    "            ax.set_title('Hyperopt trials {} vs. {}'.format(column, metric))\n",
    "            ax.set_ylabel(metric)\n",
    "            ax.set_xlabel(column)\n",
    "            for i in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "                i.set_fontsize(SMALL_FONT)  \n",
    "            for i in [ax.title, ax.xaxis.label, ax.yaxis.label]:\n",
    "                i.set_fontsize(MED_FONT)\n",
    "        fig.suptitle(plot_name, size=BIG_FONT)\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.96)\n",
    "        plt.savefig(image_name, format='svg')\n",
    "    return fig\n",
    "\n",
    "def generate_forecast_plots(forecast_data, **plot_conf):\n",
    "    images = []\n",
    "    for airport in forecast_data['Airport'].unique():\n",
    "        filtered = forecast_data[forecast_data['Airport'] == airport]\n",
    "        real_data = filtered[plot_conf['target_col']]\n",
    "        forecast_historic = filtered[filtered['is_future'] == False][plot_conf['forecast_col']]\n",
    "        forecast_future = filtered[filtered['is_future'] == True][plot_conf['forecast_col']]\n",
    "        min_scale = np.min([filtered[plot_conf['forecast_col']].min(), filtered[plot_conf['target_col']].min()])\n",
    "        forecast_boundary = filtered[filtered['is_future'] != True].index[-1]\n",
    "        with plt.style.context(style='seaborn'):\n",
    "            fig, ax = plt.subplots(1,1,figsize=plot_conf['figsize'])\n",
    "            ser1 = ax.plot(real_data, 'b-o', label='Historic Data for {} at {}'.format(\n",
    "                plot_conf['target_col'], airport))\n",
    "            ser2 = ax.plot(forecast_historic, 'r--o', label='Forecast during historic for {} at {}'.format(\n",
    "                plot_conf['target_col'], airport))\n",
    "            ser3 = ax.plot(forecast_future, 'r:o', label='Future forecast for {} at {}'.format(\n",
    "                plot_conf['target_col'], airport))\n",
    "            ax.legend(loc='upper left', fontsize=MED_FONT)\n",
    "            ax.set_title('Raw, Predicted, and Forecast data for {}'.format(airport))\n",
    "            ax.set_ylabel(plot_conf['target_col'])\n",
    "            ax.set_xlabel('Date')\n",
    "            boundary = ax.axvline(forecast_boundary, color='black')\n",
    "            bbox_conf = dict(boxstyle='round,pad=0.5', fc='ivory', ec='k', lw=0.8)\n",
    "            left_box = ax.text(forecast_boundary - relativedelta(months=1), \n",
    "                               min_scale, \n",
    "                               \"<-- Historic Data\", \n",
    "                               bbox=bbox_conf, \n",
    "                               fontsize=MED_FONT,\n",
    "                               ha='right'                              \n",
    "                              )\n",
    "            right_box = ax.text(forecast_boundary + relativedelta(months=1), \n",
    "                                min_scale, \n",
    "                                \"Forecast Data -->\", \n",
    "                                bbox=bbox_conf, \n",
    "                                fontsize=MED_FONT)\n",
    "            for i in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "                i.set_fontsize(SMALL_FONT)  \n",
    "            for i in [ax.title, ax.xaxis.label, ax.yaxis.label]:\n",
    "                i.set_fontsize(BIG_FONT)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('{}{}'.format(airport, plot_conf['image_base_name']), format='svg')\n",
    "            images.append(fig)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fde317-e45d-4cc8-a205-90e20521e56d",
   "metadata": {},
   "source": [
    "#### Minimization Function for Holt-Winters Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b78a077-4b87-4751-8f81-4936355a7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_smoothing_raw(train, test, selected_hp_values):\n",
    "    output = {}\n",
    "    model = ExponentialSmoothing(train, \n",
    "                               trend=selected_hp_values['model']['trend'],\n",
    "                               seasonal=selected_hp_values['model']['seasonal'],\n",
    "                               seasonal_periods=selected_hp_values['model']['seasonal_periods'],\n",
    "                               damped=selected_hp_values['model']['damped']\n",
    "                              )\n",
    "    model_fit = model.fit(smoothing_level=selected_hp_values['fit']['smoothing_level'],\n",
    "                          smoothing_seasonal=selected_hp_values['fit']['smoothing_seasonal'],\n",
    "                          damping_slope=selected_hp_values['fit']['damping_slope'],\n",
    "                          use_brute=selected_hp_values['fit']['use_brute'],\n",
    "                          use_boxcox=selected_hp_values['fit']['use_boxcox'],\n",
    "                          use_basinhopping=selected_hp_values['fit']['use_basinhopping'],\n",
    "                          remove_bias=selected_hp_values['fit']['remove_bias']\n",
    "                         )\n",
    "    forecast = model_fit.predict(train.index[-1], test.index[-1])\n",
    "    output['model'] = model_fit\n",
    "    output['forecast'] = forecast[1:]\n",
    "    return output\n",
    "\n",
    "# def hwes_minimization_function(selected_hp_values, train, test, loss_metric, progress):\n",
    "#     try:\n",
    "#         print(\"Evaluating with hyperparameters:\", selected_hp_values)\n",
    "#         model_results = exp_smoothing_raw(train, test, selected_hp_values)\n",
    "#         errors = calculate_errors(test, model_results['forecast'], extract_param_count_hwes(selected_hp_values))\n",
    "#         print(\"Evaluation successful with errors:\", errors)\n",
    "#         progress.update()\n",
    "#         return {'loss': errors[loss_metric], 'status': STATUS_OK}\n",
    "#     except Exception as e:\n",
    "#         print(\"Error during evaluation:\", e)\n",
    "#         return {'loss': float('inf'), 'status': STATUS_FAIL, 'exception': str(e)}\n",
    "\n",
    "def hwes_minimization_function(selected_hp_values, train, test, loss_metric, progress):\n",
    "    try:\n",
    "        print(\"Evaluating with hyperparameters:\", selected_hp_values)\n",
    "        model_results = exp_smoothing_raw(train, test, selected_hp_values)\n",
    "        print(\"Model results:\", model_results)\n",
    "        errors = calculate_errors(test, model_results['forecast'], extract_param_count_hwes(selected_hp_values))\n",
    "        print(\"Evaluation successful with errors:\", errors)\n",
    "        progress.update()\n",
    "        return {'loss': errors[loss_metric], 'status': STATUS_OK}\n",
    "    except Exception as e:\n",
    "        print(\"Error during evaluation:\", e)\n",
    "        return {'loss': float('inf'), 'status': STATUS_FAIL, 'exception': str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a041004b-5614-4bf2-9c35-3238b7df9899",
   "metadata": {},
   "source": [
    "### Hyperopt Tuning Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e88c32ed-d916-414c-a536-76280a9c8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tuning(train, test, **params):\n",
    "    print(\"Starting tuning with parameters:\", params)\n",
    "    print(\"Train data shape:\", train.shape)\n",
    "    print(\"Test data shape:\", test.shape)\n",
    "    print(\"First few rows of train data:\", train.head())\n",
    "    print(\"First few rows of test data:\", test.head())\n",
    "    param_count = extract_param_count_hwes(params['tuning_space'])\n",
    "    output = {}\n",
    "    trial_run = Trials()\n",
    "    try:\n",
    "        tuning = fmin(partial(params['minimization_function'], \n",
    "                              train=train, \n",
    "                              test=test,\n",
    "                              loss_metric=params['loss_metric'],\n",
    "                              progress=params['progress']\n",
    "                             ), \n",
    "                      params['tuning_space'], \n",
    "                      algo=params['hpopt_algo'], \n",
    "                      max_evals=params['iterations'], \n",
    "                      trials=trial_run,\n",
    "                      verbose=params['verbose'],\n",
    "                      catch_eval_exceptions=True\n",
    "                     )\n",
    "        print(\"Completed Hyperopt tuning.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error during Hyperopt tuning:\", e)\n",
    "        raise e\n",
    "    \n",
    "    if len(trial_run) == 0:\n",
    "        raise Exception(\"No evaluation tasks were completed. Please check the configuration and data.\")\n",
    "    \n",
    "    best_run = space_eval(params['tuning_space'], tuning)\n",
    "    print(\"Best hyperparameters found:\", best_run)\n",
    "    \n",
    "    try:\n",
    "        generated_model = params['forecast_algo'](train, test, best_run)\n",
    "        extracted_trials = extract_hyperopt_trials(trial_run, params['tuning_space'], params['loss_metric'])\n",
    "        output['best_hp_params'] = best_run\n",
    "        output['best_model'] = generated_model['model']\n",
    "        output['hyperopt_trials_data'] = extracted_trials\n",
    "        output['hyperopt_trials_visualization'] = generate_hyperopt_report(extracted_trials, \n",
    "                                                                           params['loss_metric'], \n",
    "                                                                           params['hyperopt_title'], \n",
    "                                                                           params['hyperopt_image_name'])\n",
    "        output['forecast_data'] = generated_model['forecast']\n",
    "        output['series_prediction'] = build_future_forecast(generated_model['model'],\n",
    "                                                            params['airport_name'],\n",
    "                                                            params['future_forecast_periods'],\n",
    "                                                            params['train_split_cutoff_months'],\n",
    "                                                            params['target_name']\n",
    "                                                           )\n",
    "        output['plot_data'] = plot_predictions(test, \n",
    "                                               generated_model['forecast'], \n",
    "                                               param_count,\n",
    "                                               params['name'], \n",
    "                                               params['target_name'], \n",
    "                                               params['image_name'])\n",
    "    except Exception as e:\n",
    "        print(\"Error during model generation or plotting:\", e)\n",
    "        raise e\n",
    "    \n",
    "    return output\n",
    "\n",
    "def run_all_models(**config):\n",
    "    print(\"Starting model training for all airports with configuration:\", config)\n",
    "    all_data = pull_raw_airport_data(config['source_data'])\n",
    "    model_outputs = {}\n",
    "    airports = get_all_airports_from_df(all_data)\n",
    "    base = config['base_config']\n",
    "    \n",
    "    for airport in airports:\n",
    "        print(f\"Processing airport: {airport}\")\n",
    "        data = get_airport_data_from_df(all_data, config['series_freq'], airport)\n",
    "        \n",
    "        if validate_data_counts(data, all_model_config['train_split_cutoff_months']):\n",
    "            print(f\"Starting tuning of Airport {airport}\")\n",
    "            progress = tqdm(total = base['iterations'])\n",
    "            run_config = {\n",
    "                'minimization_function': base['minimization_function'],\n",
    "                'tuning_space': base['tuning_space'],\n",
    "                'forecast_algo': base['forecast_algo'],\n",
    "                'loss_metric': base['loss_metric'],\n",
    "                'hpopt_algo': base['hpopt_algo'],\n",
    "                'iterations': base['iterations'],\n",
    "                'name': f\"{base['base_name']} {airport}\",\n",
    "                'target_name': base['target_name'],\n",
    "                'image_name': f\"{base['fit_base_image_name']}_{airport}.svg\",\n",
    "                'airport_name': airport,\n",
    "                'future_forecast_periods': config['future_forecast_periods'],\n",
    "                'train_split_cutoff_months': config['train_split_cutoff_months'],\n",
    "                'hyperopt_title': f\"{airport}_Hyperopt Training Report\",\n",
    "                'hyperopt_image_name': f\"{base['tuning_base_image_name']}_{airport}.svg\",\n",
    "                'verbose': base['verbose'],\n",
    "                'progress': progress\n",
    "            }\n",
    "            \n",
    "            train, test = generate_splits_by_months(data, config['train_split_cutoff_months'])\n",
    "            \n",
    "            try:\n",
    "                if base['verbose']:\n",
    "                    model_outputs[airport] = run_tuning(train=train[config['forecast_field']], \n",
    "                                                        test=test[config['forecast_field']], \n",
    "                                                        **run_config)\n",
    "                else:\n",
    "                    with suppress_annoying_prints():\n",
    "                        model_outputs[airport] = run_tuning(train=train[config['forecast_field']], \n",
    "                                                            test=test[config['forecast_field']], \n",
    "                                                            **run_config)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during tuning for airport {airport}: {e}\")\n",
    "                raise e\n",
    "            finally:\n",
    "                progress.close()\n",
    "                \n",
    "    return model_outputs\n",
    "\n",
    "def build_forecast_dataset(run_data, **run_config):\n",
    "    run_keys = run_data.keys()\n",
    "    coll = []\n",
    "    for airport in run_keys:\n",
    "        forecast_df = pd.DataFrame(run_data[airport]['series_prediction'], \n",
    "                                   columns=['{}_pred'.format(run_config['forecast_field']), 'Airport', 'is_future'])\n",
    "        data = get_airport_data(run_config['source_data'], run_config['series_freq'], airport)\n",
    "        train, test = generate_splits_by_months(data, run_config['train_split_cutoff_months'])\n",
    "        coll.append(forecast_df.merge(test[run_config['forecast_field']], \n",
    "                                      how='left', right_index=True, left_index=True))\n",
    "    return pd.concat(*[coll])\n",
    "\n",
    "def build_future_forecast(model, airport, future_periods, test_periods, forecast_column):\n",
    "    forecast_df = pd.DataFrame(model.forecast(test_periods + future_periods), \n",
    "                               columns=['{}_pred'.format(forecast_column)])\n",
    "    forecast_df['Airport'] = airport\n",
    "    series_end = forecast_df[:test_periods].index.values[-1]\n",
    "    forecast_df['is_future'] = np.where(forecast_df.index > series_end, True, False)\n",
    "    return forecast_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe8158c-2b96-4365-8dc9-0f0ba08054fb",
   "metadata": {},
   "source": [
    "#### Hyperopt Exploration Space Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f5239c82-d112-4b08-a8ce-d07b7d0ea5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpopt_space = {\n",
    "    'model': {\n",
    "        'trend': 'add',\n",
    "        'seasonal': 'add',\n",
    "        'seasonal_periods': 12,\n",
    "        'damped': True\n",
    "    },\n",
    "    'fit': {\n",
    "        'smoothing_level': 0.5,\n",
    "        'smoothing_seasonal': 0.5,\n",
    "        'damping_slope': 0.5,\n",
    "        'use_brute': False,\n",
    "        'use_boxcox': False,\n",
    "        'use_basinhopping': False,\n",
    "        'remove_bias': False\n",
    "    }\n",
    "}\n",
    "base_config = {\n",
    "              'minimization_function': hwes_minimization_function,\n",
    "              'tuning_space': hpopt_space,\n",
    "              'forecast_algo': exp_smoothing_raw,\n",
    "              'loss_metric': 'bic',\n",
    "              'hpopt_algo': tpe.suggest,\n",
    "              'iterations': 400,\n",
    "              'base_name': 'Total Passengers HPOPT',\n",
    "              'target_name': 'Total Passengers',\n",
    "              'fit_base_image_name': 'total_passengers_validation',\n",
    "              'tuning_base_image_name': 'total_passengers_hpopt',\n",
    "              'verbose': False\n",
    "}\n",
    "all_model_config = {\n",
    "    'source_data': DATA_PATH,\n",
    "    'train_split_cutoff_months': 12,\n",
    "    'future_forecast_periods': 36,\n",
    "    'series_freq': 'MS',\n",
    "    'forecast_field': 'Total Passengers',\n",
    "    'base_config': base_config\n",
    "}\n",
    "plot_conf = {\n",
    "    'forecast_col': 'Total Passengers_pred',\n",
    "    'target_col': 'Total Passengers',\n",
    "    'image_base_name': '_forecast.svg',\n",
    "    'figsize': (16,12)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4c4f2767-03db-4d1d-beb7-0991162dc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airports = run_all_models(**all_model_config)\n",
    "\n",
    "all_forecasts = build_forecast_dataset(all_airports, **all_model_config)\n",
    "\n",
    "forecast_plots = generate_forecast_plots(all_forecasts, **plot_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db04644e-d6e9-45dc-89d4-16fb8c5bde3e",
   "metadata": {},
   "source": [
    "#### Return Rype of run_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4e3d98a4-3436-48fb-bdec-70a51c2d4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd76e5-9711-4e16-86f2-e4c15679f28c",
   "metadata": {},
   "source": [
    "#### What Hyperopt is Doing with its Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17991ff-fe7e-4c8e-8b81-dfaacebf5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_config2 = copy.deepcopy(all_model_config)\n",
    "\n",
    "all_model_config2['base_config']['verbose'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3160eac-c36c-482c-9653-022b1666e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time timed_tuning = run_all_models(**all_model_config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8998ac-57d0-468f-b940-3fdf960ffd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c7e41e-552c-4698-9e06-5535e38920bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tuning(train, test, **params):\n",
    "    param_count = extract_param_count_hwes(params['tuning_space'])\n",
    "    output = {}\n",
    "    trial_run = Trials()\n",
    "    tuning = fmin(partial(params['minimization_function'], \n",
    "                          train=train, \n",
    "                          test=test,\n",
    "                          loss_metric=params['loss_metric'],\n",
    "                          progress=params['progress']\n",
    "                         ), \n",
    "                  params['tuning_space'], \n",
    "                  algo=params['hpopt_algo'], \n",
    "                  max_evals=params['iterations'], \n",
    "                  trials=trial_run,\n",
    "                  verbose=params['verbose'],\n",
    "                  catch_eval_exceptions=True\n",
    "                 )\n",
    "    if len(trial_run) == 0:\n",
    "        raise Exception(\"No evaluation tasks were completed. Please check the configuration and data.\")\n",
    "    \n",
    "    best_run = space_eval(params['tuning_space'], tuning)\n",
    "    generated_model = params['forecast_algo'](train, test, best_run)\n",
    "    extracted_trials = extract_hyperopt_trials(trial_run, params['tuning_space'], params['loss_metric'])\n",
    "    output['best_hp_params'] = best_run\n",
    "    output['best_model'] = generated_model['model']\n",
    "    output['hyperopt_trials_data'] = extracted_trials\n",
    "    output['hyperopt_trials_visualization'] = generate_hyperopt_report(extracted_trials, \n",
    "                                                                       params['loss_metric'], \n",
    "                                                                       params['hyperopt_title'], \n",
    "                                                                       params['hyperopt_image_name'])\n",
    "    output['forecast_data'] = generated_model['forecast']\n",
    "    output['series_prediction'] = build_future_forecast(generated_model['model'],\n",
    "                                                        params['airport_name'],\n",
    "                                                        params['future_forecast_periods'],\n",
    "                                                        params['train_split_cutoff_months'],\n",
    "                                                        params['target_name']\n",
    "                                                       )\n",
    "    output['plot_data'] = plot_predictions(test, \n",
    "                                           generated_model['forecast'], \n",
    "                                           param_count,\n",
    "                                           params['name'], \n",
    "                                           params['target_name'], \n",
    "                                           params['image_name'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26494f8e-fa0a-48de-9318-fcf82227cd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795377a-c363-489d-bb2b-ce0938cf12d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
