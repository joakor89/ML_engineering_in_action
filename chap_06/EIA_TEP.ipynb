{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efa6f15-d18d-436c-9d46-6678ea7b5c41",
   "metadata": {},
   "source": [
    "# Experimentation in Action: Testing & Evaluating a Project\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "627bd56a-4e98-4953-89b7-3b45a67fcbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Mathematics\n",
    "from math import sqrt\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score \n",
    "\n",
    "# Dates\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# Statistical Models\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb2246ec-70a0-4c74-bcd6-3ccde89da0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available styles in matplotlib:\n",
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "# Check available styles in matplotlib\n",
    "available_styles = plt.style.available\n",
    "print(\"Available styles in matplotlib:\")\n",
    "print(available_styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3f47b21-0c39-44e7-86ba-4cd8e09be9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using style: seaborn-v0_8\n"
     ]
    }
   ],
   "source": [
    "# Select a specific seaborn style if available, otherwise use default\n",
    "seaborn_style = next((style for style in available_styles if style.startswith('seaborn-v0_8')), 'default')\n",
    "print(f\"\\nUsing style: {seaborn_style}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544aa1f-2f24-42f9-8492-f947ffd7fea8",
   "metadata": {},
   "source": [
    "#### Loading Data & Style Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "586dcdf1-29a4-46de-a56b-00925cabf8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/isisromero/desktop/MLEIA/chap_06/air-passenger-traffic-per-month-port-authority-of-ny-nj-beginning-1977.csv'\n",
    "AIRPORT_FIELD = 'Airport Code'\n",
    "\n",
    "def apply_index_freq(data, freq):\n",
    "    return data.asfreq(freq)\n",
    "\n",
    "def pull_raw_airport_data(file_location):\n",
    "    raw = pd.read_csv(file_location)\n",
    "    raw = raw.copy(deep=False)\n",
    "    raw['Month'] = pd.to_datetime(raw['Month'], format='%b').dt.month\n",
    "    raw['Day'] = 1\n",
    "    raw['date'] = pd.to_datetime(raw[['Year', 'Month', 'Day']])\n",
    "    raw.set_index('date', inplace=True)\n",
    "    raw.index = pd.DatetimeIndex(raw.index.values, freq=raw.index.inferred_freq)\n",
    "    asc = raw.sort_index()\n",
    "    return asc\n",
    "\n",
    "def get_airport_data(airport, file_location): \n",
    "    all_data = pull_raw_airport_data(file_location)\n",
    "    filtered = all_data[all_data[AIRPORT_FIELD] == airport]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be61ff-73b8-4eaa-b6ce-908b3de72edc",
   "metadata": {},
   "source": [
    "##### Exponential Smoothing and Error Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ab2c51c-a42d-49ad-a2e7-aec62c52b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_smoothing(raw_series, alpha=0.05): \n",
    "    output = [raw_series.iloc[0]]\n",
    "    for i in range(1, len(raw_series)):\n",
    "        output.append(raw_series.iloc[i] * alpha + (1-alpha) * output[i-1])\n",
    "    return pd.Series(output, index=raw_series.index)\n",
    "\n",
    "def calculate_mae(raw_series, smoothed_series, window, scale):\n",
    "    res = {}\n",
    "    mae_value = mean_absolute_error(raw_series[window:], smoothed_series[window:])\n",
    "    res['mae'] = mae_value\n",
    "    deviation = np.std(raw_series[window:] - smoothed_series[window:])\n",
    "    res['stddev'] = deviation\n",
    "    yhat = mae_value + scale * deviation\n",
    "    res['yhat_low'] = smoothed_series - yhat\n",
    "    res['yhat_high'] = smoothed_series + yhat\n",
    "    return res\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def calculate_errors(y_true, y_pred):\n",
    "    error_scores = {}\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    error_scores['mae'] = mean_absolute_error(y_true, y_pred)\n",
    "    error_scores['mape'] = mape(y_true, y_pred)\n",
    "    error_scores['mse'] = mse\n",
    "    error_scores['rmse'] = sqrt(mse)\n",
    "    error_scores['explained_var'] = explained_variance_score(y_true, y_pred)\n",
    "    error_scores['r2'] = r2_score(y_true, y_pred)\n",
    "    return error_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a128af7-8448-43a2-ae50-481570baf549",
   "metadata": {},
   "source": [
    "#### Setting Function for Generating Exponential Smoothing & Moving Average Data & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e02bba5-a06a-46e8-be4d-7564ecaa6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed_time_plots(time_series, time_series_name, image_name, smoothing_window, exp_alpha=0.05, \n",
    "                        yhat_scale=1.96, style='default', plot_size=(16, 24)):\n",
    "    reference_collection = {}\n",
    "    ts = pd.Series(time_series)\n",
    "    with plt.style.context(style):\n",
    "        fig, axes = plt.subplots(3, 1, figsize=plot_size)  \n",
    "        plt.subplots_adjust(hspace=0.3)\n",
    "        \n",
    "        # Series for Rolling Moving Average over a Specified Window \n",
    "        moving_avg = ts.rolling(window=smoothing_window).mean()\n",
    "        \n",
    "        # Exponentially Smoothed Average Series \n",
    "        exp_smoothed = exp_smoothing(ts, exp_alpha)\n",
    "        \n",
    "        # MAE and the Error Estimations for Moving Average\n",
    "        res = calculate_mae(time_series, moving_avg, smoothing_window, yhat_scale)\n",
    "        \n",
    "        # MAE and Error Estimations on Exponentially Smoothed Data\n",
    "        res_exp = calculate_mae(time_series, exp_smoothed, smoothing_window, yhat_scale)\n",
    "        \n",
    "        # Pandas Series from the Exponentially Smoothed Data\n",
    "        exp_data = pd.Series(exp_smoothed, index=time_series.index)\n",
    "        \n",
    "        # Pandas Series for the StdDev Error Trends\n",
    "        exp_yhat_low_data = pd.Series(res_exp['yhat_low'], index=time_series.index)\n",
    "        exp_yhat_high_data = pd.Series(res_exp['yhat_high'], index=time_series.index)\n",
    "        \n",
    "        # Raw Data\n",
    "        axes[0].plot(ts, '-', label='Trend for {}'.format(time_series_name))\n",
    "        axes[0].legend(loc='upper left')\n",
    "        axes[0].set_title('Raw Data trend for {}'.format(time_series_name))\n",
    "        axes[0].grid(True)\n",
    "        \n",
    "        # Moving Average Data\n",
    "        axes[1].plot(ts, '-', label='Trend for {}'.format(time_series_name))\n",
    "        axes[1].plot(moving_avg, 'g-', label='Moving Average with window: {}'.format(smoothing_window))\n",
    "        axes[1].plot(res['yhat_high'], 'r--', label='yhat bounds')\n",
    "        axes[1].plot(res['yhat_low'], 'r--')\n",
    "        axes[1].set_title('Moving Average Trend for window: {} with MAE of: {:.1f}'.format(smoothing_window, res['mae'])) \n",
    "        axes[1].legend(loc='upper left')\n",
    "        axes[1].grid(True)\n",
    "        \n",
    "        # Exponentially Smoothed Data\n",
    "        axes[2].plot(ts, '-', label='Trend for {}'.format(time_series_name))\n",
    "        axes[2].legend(loc='upper left')\n",
    "        axes[2].plot(exp_data, 'g-', label='Exponential Smoothing with alpha: {}'.format(exp_alpha))\n",
    "        axes[2].plot(exp_yhat_high_data, 'r--', label='yhat bounds')\n",
    "        axes[2].plot(exp_yhat_low_data, 'r--')\n",
    "        axes[2].set_title('Exponential Smoothing Trend for alpha: {} with MAE of: {:.1f}'.format(exp_alpha, res_exp['mae']))\n",
    "        axes[2].legend(loc='upper left')\n",
    "        axes[2].grid(True)\n",
    "        \n",
    "        plt.savefig(image_name, format='svg')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        reference_collection['plots'] = fig\n",
    "        reference_collection['moving_average'] = moving_avg\n",
    "        reference_collection['exp_smooth'] = exp_smoothed\n",
    "        \n",
    "        return reference_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eaa19d-7c51-4417-b9a3-4d4a77c7e14d",
   "metadata": {},
   "source": [
    "#### Smoothing Function for Series Data & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a3e2109-67e3-40cd-b781-a910893d1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewr_data = get_airport_data('EWR', DATA_PATH)\n",
    "\n",
    "ewr_reference = smoothed_time_plots(ewr_data['International Passengers'], 'Newark International', \n",
    "                                    'newark_dom_smooth_plot.svg', 12, exp_alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15624c28-d050-4795-8d1a-d2c387912955",
   "metadata": {},
   "source": [
    "#### Standard Error Calculations for Scoring Forecast Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c0aca6-15c3-4c8a-b417-884e2c28a970",
   "metadata": {},
   "source": [
    "#### Prediction Forecast Plotting with Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fea5d7fa-0fb3-40c9-8b09-f8a49d38abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_true, y_pred, time_series_name, value_name, image_name, style='default', plot_size=(16, 12)):\n",
    "    validation_output = {} \n",
    "    error_values = calculate_errors(y_true, y_pred)\n",
    "    validation_output['errors'] = error_values\n",
    "    \n",
    "    text_str = '\\n'.join((\n",
    "        'mae = {:.3f}'.format(error_values['mae']),\n",
    "        'mape = {:.3f}'.format(error_values['mape']),\n",
    "        'mse = {:.3f}'.format(error_values['mse']),\n",
    "        'rmse = {:.3f}'.format(error_values['rmse']),\n",
    "        'explained var = {:.3f}'.format(error_values['explained_var']),\n",
    "        'r squared = {:.3f}'.format(error_values['r2']),\n",
    "    )) \n",
    "    with plt.style.context(style):\n",
    "        fig, axes = plt.subplots(1, 1, figsize=plot_size)\n",
    "        axes.plot(y_true, 'b-', label='Test data for {}'.format(time_series_name))\n",
    "        axes.plot(y_pred, 'r-', label='Forecast data for {}'.format(time_series_name))\n",
    "        axes.legend(loc='upper left')\n",
    "        axes.set_title('Raw and Predicted data trend for {}'.format(time_series_name))\n",
    "        axes.set_ylabel(value_name)\n",
    "        axes.set_xlabel(y_true.index.name)\n",
    "        \n",
    "        # Bounding Box Overlay's Set-Up\n",
    "        props = dict(boxstyle='round', facecolor='oldlace', alpha=0.5)\n",
    "        axes.text(0.05, 0.9, text_str, transform=axes.transAxes, fontsize=12, verticalalignment='top', bbox=props)\n",
    "        validation_output['plot'] = fig\n",
    "        plt.savefig(image_name, format='svg')\n",
    "        plt.tight_layout()\n",
    "    return validation_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f5ad0f-d2b6-4f59-bc4d-89d5ab040837",
   "metadata": {},
   "source": [
    "#### Split Procedure: Train & Test Datasets (with Validation check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b9fb1bd-1707-4513-9c19-e46635a42854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_correctness(data, train, test):\n",
    "    assert data.size == train.size + test.size, \\\n",
    "    \"Train count {} and test count {} did not match to source count {}\".format(train.size, test.size, data.size)\n",
    "\n",
    "def generate_splits(data, date):\n",
    "    parsed_date = parse(date, fuzzy=True)\n",
    "    nearest_date = data[:parsed_date].iloc[0].name\n",
    "    train = data[:nearest_date]\n",
    "    test = data[nearest_date:][1:]\n",
    "    split_correctness(data, train, test)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "808ac1ec-1707-4473-990b-290b8302060f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Domestic Passengers</th>\n",
       "      <th>International Passengers</th>\n",
       "      <th>Total Passengers</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1977-01-01</th>\n",
       "      <td>JFK</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>856626</td>\n",
       "      <td>630962</td>\n",
       "      <td>1487588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airport Code  Year  Month  Domestic Passengers  \\\n",
       "1977-01-01          JFK  1977      1               856626   \n",
       "\n",
       "            International Passengers  Total Passengers  Day  \n",
       "1977-01-01                    630962           1487588    1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jfk_raw_data = get_airport_data('JFK', DATA_PATH)\n",
    "\n",
    "jfk_train_check, jfk_test_check = generate_splits(jfk_raw_data, \"2010-04-13\")\n",
    "jfk_train_check.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "392051de-c7ad-401d-ad62-f6e28398fe38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Domestic Passengers</th>\n",
       "      <th>International Passengers</th>\n",
       "      <th>Total Passengers</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1977-01-01</th>\n",
       "      <td>JFK</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>856626</td>\n",
       "      <td>630962</td>\n",
       "      <td>1487588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airport Code  Year  Month  Domestic Passengers  \\\n",
       "1977-01-01          JFK  1977      1               856626   \n",
       "\n",
       "            International Passengers  Total Passengers  Day  \n",
       "1977-01-01                    630962           1487588    1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jfk_train_check2, jfk_test_check2 = generate_splits(jfk_raw_data, \"3 march 2009\")\n",
    "jfk_train_check2.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f711bd8f-8df1-4932-a968-de322a29cd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Domestic Passengers</th>\n",
       "      <th>International Passengers</th>\n",
       "      <th>Total Passengers</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1977-01-01</th>\n",
       "      <td>JFK</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>856626</td>\n",
       "      <td>630962</td>\n",
       "      <td>1487588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airport Code  Year  Month  Domestic Passengers  \\\n",
       "1977-01-01          JFK  1977      1               856626   \n",
       "\n",
       "            International Passengers  Total Passengers  Day  \n",
       "1977-01-01                    630962           1487588    1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_being_ridiculous_train, ben_being_ridiculous_test = generate_splits(jfk_raw_data, \"The 4th of July 06\")\n",
    "ben_being_ridiculous_train.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f4da938-7891-4e7a-8c7f-2dc1eb8886c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae': 29740.303650581278, 'mape': 9.34167357293583, 'mse': 1606386841.6365783, 'rmse': 40079.75600769768, 'explained_var': 0.9882205042782021, 'r2': 0.9881903025377015}\n"
     ]
    }
   ],
   "source": [
    "errors = calculate_errors(ewr_data['International Passengers'], ewr_reference['exp_smooth'])\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a0189be-ce69-4920-bd0f-09b752305b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output = plot_predictions(ewr_data['International Passengers'], ewr_reference['exp_smooth'], \n",
    "                               'Newark International', \n",
    "                               'Passengers', \n",
    "                               'newark_predictions_plot.svg', style=seaborn_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a075157b-ad46-403c-9666-f87dbcd24992",
   "metadata": {},
   "outputs": [],
   "source": [
    "jfk = get_airport_data('JFK', DATA_PATH)\n",
    "jfk = apply_index_freq(jfk, 'MS')\n",
    "train, test = generate_splits(jfk, '2006-07-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a087aa59-b3b6-453e-a4cf-3b1a2f25508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_model = VAR(train[['Domestic Passengers', 'International Passengers']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a22f0a0-1607-4a98-8fa2-b2f353b51ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jfk = get_airport_data('JFK', DATA_PATH)\n",
    "jfk = apply_index_freq(jfk, 'MS')\n",
    "train, test = generate_splits(jfk, '2006-07-08')\n",
    "\n",
    "var_model = VAR(train[['Domestic Passengers', 'International Passengers']])\n",
    "\n",
    "var_model.select_order(12)\n",
    "\n",
    "var_fit = var_model.fit()\n",
    "\n",
    "lag_order = var_fit.k_ar\n",
    "\n",
    "var_pred = var_fit.forecast(test[['Domestic Passengers', 'International Passengers']].values[-lag_order:], \n",
    "                            test.index.size)\n",
    "\n",
    "var_pred_dom = pd.Series(np.asarray(list(zip(*var_pred))[0], dtype=np.float32), index=test.index)\n",
    "var_pred_intl = pd.Series(np.asarray(list(zip(*var_pred))[1], dtype=np.float32), index=test.index)\n",
    "\n",
    "var_prediction_score = plot_predictions(test['Domestic Passengers'], \n",
    "                                        var_pred_dom, \n",
    "                                        \"VAR model Domestic Passengers JFK\", \n",
    "                                        \"Domestic Passengers\", \n",
    "                                        \"var_jfk_dom.svg\")\n",
    "\n",
    "var_prediction_score_intl = plot_predictions(test['International Passengers'], \n",
    "                                        var_pred_intl, \n",
    "                                        \"VAR model International Passengers JFK\", \n",
    "                                        \"International Passengers\", \n",
    "                                        \"var_jfk_intl.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4c6d09-2562-49b8-a585-ef2b2ce77c20",
   "metadata": {},
   "source": [
    "#### VAR another Shot after read Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6d7420f-8166-4bbe-a8ee-ef38888c3c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_model = VAR(train[['Domestic Passengers', 'International Passengers']])\n",
    "var_model.select_order(12)\n",
    "var_fit = var_model.fit(12)\n",
    "\n",
    "lag_order = var_fit.k_ar\n",
    "\n",
    "var_pred = var_fit.forecast(test[['Domestic Passengers', 'International Passengers']].values[-lag_order:], test.index.size)\n",
    "var_pred_dom = pd.Series(np.asarray(list(zip(*var_pred))[0], dtype=np.float32), index=test.index)\n",
    "var_pred_intl = pd.Series(np.asarray(list(zip(*var_pred))[1], dtype=np.float32), index=test.index)\n",
    "\n",
    "var_prediction_score = plot_predictions(test['Domestic Passengers'], \n",
    "                                        var_pred_dom, \n",
    "                                        \"VAR model Domestic Passengers JFK\", \n",
    "                                        \"Domestic Passengers\", \n",
    "                                        \"var_jfk_dom_lag12.svg\")\n",
    "\n",
    "var_prediction_score_intl = plot_predictions(test['International Passengers'], \n",
    "                                        var_pred_intl, \n",
    "                                        \"VAR model International Passengers JFK\", \n",
    "                                        \"International Passengers\", \n",
    "                                        \"var_jfk_intl_lag12.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69443075-f0c3-4651-a12d-d389b4ad6fc7",
   "metadata": {},
   "source": [
    "#### Stationarity Adjusted Predictions with a VAR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "205387fc-a421-4b45-8810-71eee9d04c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jfk_stat = get_airport_data('JFK', DATA_PATH)\n",
    "jfk_stat = apply_index_freq(jfk, 'MS')\n",
    "\n",
    "\n",
    "jfk_stat['Domestic Diff'] = np.log(jfk_stat['Domestic Passengers']).diff()\n",
    "jfk_stat['International Diff'] = np.log(jfk_stat['International Passengers']).diff()\n",
    "\n",
    "jfk_stat = jfk_stat.dropna()\n",
    "train, test = generate_splits(jfk_stat, '2006-07-08')\n",
    "var_model = VAR(train[['Domestic Diff', 'International Diff']])\n",
    "var_model.select_order(6)\n",
    "var_fit = var_model.fit(12)\n",
    "lag_order = var_fit.k_ar\n",
    "var_pred = var_fit.forecast(test[['Domestic Diff', 'International Diff']].values[-lag_order:], test.index.size)\n",
    "var_pred_dom = pd.Series(np.asarray(list(zip(*var_pred))[0], dtype=np.float32), index=test.index)\n",
    "var_pred_intl = pd.Series(np.asarray(list(zip(*var_pred))[1], dtype=np.float32), index=test.index)\n",
    "\n",
    "\n",
    "var_pred_dom_expanded = np.exp(var_pred_dom.cumsum()) * test['Domestic Passengers'][0]\n",
    "var_pred_intl_expanded = np.exp(var_pred_intl.cumsum()) * test['International Passengers'][0]\n",
    "var_prediction_score = plot_predictions(test['Domestic Passengers'], \n",
    "                                        var_pred_dom_expanded, \n",
    "                                        \"VAR model Domestic Passengers JFK Diff\", \n",
    "                                        \"Domestic Diff\", \n",
    "                                        \"var_jfk_dom_lag12_diff.svg\")\n",
    "var_prediction_score_intl = plot_predictions(test['International Passengers'], \n",
    "                                        var_pred_intl_expanded, \n",
    "                                        \"VAR model International Passengers JFK Diff\", \n",
    "                                        \"International Diff\", \n",
    "                                        \"var_jfk_intl_lag12_diff.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb10980-90f7-4fac-9646-fea5c5555d38",
   "metadata": {},
   "source": [
    "#### A Rough First-Pass at a VAR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e436c316-cea9-47ae-abb4-cb509bbd7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jfk_linear = get_airport_data('JFK', DATA_PATH)\n",
    "\n",
    "jfk_linear['months_from_start'] = (jfk_linear.index - jfk_linear.index[0])/np.timedelta64(1, 'M')\n",
    "jfk_linear['years_from_start'] = (jfk_linear['Year'] - jfk_linear['Year'][0])\n",
    "jfk_linear['holiday_travel'] = (jfk_linear['Month'] >= 9) * 1\n",
    "\n",
    "X = jfk_linear[['months_from_start', 'years_from_start', 'holiday_travel']]\n",
    "Y = jfk_linear[['Domestic Passengers']]\n",
    "\n",
    "date_cutoff = '2006-06-10'\n",
    "X_train, X_test = generate_splits(X, date_cutoff)\n",
    "Y_train, Y_test = generate_splits(Y, date_cutoff)\n",
    "Y_train_arr = Y_train.values.ravel()\n",
    "Y_test_arr = Y_test.values.ravel()\n",
    "\n",
    "lr = LinearRegression(\n",
    "    fit_intercept=False,\n",
    "    normalize=False\n",
    ").fit(X_train, Y_train_arr)\n",
    "\n",
    "lr_validate = Y_test.copy(deep=False)\n",
    "lr_validate['prediction'] = lr.predict(X_test)\n",
    "\n",
    "ridge = RidgeCV(\n",
    "    alphas=[0.1, 0.5, 0.7, 0.95, 1.0, 10.0],\n",
    "    fit_intercept=False,\n",
    "    normalize=True,\n",
    "    gcv_mode='auto' # 'svd', 'eigen'\n",
    ").fit(X_train, Y_train_arr)\n",
    "\n",
    "ridge_validate = Y_test.copy(deep=False)\n",
    "ridge_validate['prediction'] = ridge.predict(X_test)\n",
    "\n",
    "lasso = LassoCV(\n",
    "    eps=1e-3,\n",
    "    n_alphas=100,\n",
    "    fit_intercept=False,\n",
    "    normalize=False,\n",
    "    precompute='auto',\n",
    "    tol=1e-8,\n",
    "    selection='cyclic', #cyclic\n",
    "    random_state=42\n",
    ").fit(X_train, Y_train_arr)\n",
    "\n",
    "lasso_validate = Y_test.copy(deep=False)\n",
    "lasso_validate['prediction'] = lasso.predict(X_test)\n",
    "\n",
    "elastic = ElasticNetCV(\n",
    "    l1_ratio=[1e-6, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 1.0],\n",
    "    n_alphas=100,\n",
    "    fit_intercept=False,\n",
    "    normalize=False,\n",
    "    precompute='auto',\n",
    "    tol=1e-4,\n",
    "    positive=False,\n",
    "    selection='random', #cyclic\n",
    "    random_state=42\n",
    ").fit(X_train, Y_train_arr)\n",
    "\n",
    "elastic_validate = Y_test.copy(deep=False)\n",
    "elastic_validate['prediction'] = elastic.predict(X_test)\n",
    "\n",
    "\n",
    "ensemble = Y_test.copy(deep=False)\n",
    "ensemble['ols'] = lr.predict(X_test)\n",
    "ensemble['ridge'] = ridge.predict(X_test)\n",
    "ensemble['lasso'] = lasso.predict(X_test)\n",
    "ensemble['elastic'] = lasso.predict(X_test)\n",
    "ensemble['prediction'] = ensemble[['ols', 'ridge', 'lasso', 'elastic']].mean(axis=1)\n",
    "\n",
    "\n",
    "ols_plot = plot_predictions(Y_test['Domestic Passengers'], lr_validate['prediction'], \n",
    "                 'OLS Regression JFK Domestic','Domestic Passengers', 'ols_reg.svg')\n",
    "\n",
    "\n",
    "ridge_plot = plot_predictions(Y_test['Domestic Passengers'], ridge_validate['prediction'], \n",
    "                 'Ridge Regression JFK Domestic', 'Domestic Passengers', 'ridge.svg')\n",
    "\n",
    "\n",
    "lasso_plot = plot_predictions(Y_test['Domestic Passengers'], lasso_validate['prediction'], \n",
    "                 'Lasso Regression JFK Domestic', 'Domestic Passengers', 'lasso.svg')\n",
    "\n",
    "\n",
    "enet_plot = plot_predictions(Y_test['Domestic Passengers'], elastic_validate['prediction'], \n",
    "                 'ElasticNet Regression JFK Domestic', 'Domestic Passengers', 'enet.svg')\n",
    "\n",
    "\n",
    "ensemble_plot = plot_predictions(Y_test['Domestic Passengers'], ensemble['prediction'], \n",
    "                 'Ensemble Regression JFK Domestic', 'Domestic Passengers', 'ensemble.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a721ed9e-d70e-45f1-9027-7beb91e25d8b",
   "metadata": {},
   "source": [
    "#### Final State of the ARIMA Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "277933b5-3c56-4641-91da-aa2c6ddce4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jfk_arima = get_airport_data('JFK', DATA_PATH)\n",
    "\n",
    "jfk_arima = apply_index_freq(jfk_arima, 'MS')\n",
    "train, test = generate_splits(jfk_arima, '2006-07-08')\n",
    "\n",
    "arima_model = ARIMA(train['Domestic Passengers'], order=(48,1,1), enforce_stationarity=False, trend='c')\n",
    "arima_model_intl = ARIMA(train['International Passengers'], order=(48,1,1), enforce_stationarity=False, trend='c')\n",
    "\n",
    "arima_fit = arima_model.fit()\n",
    "arima_fit_intl = arima_model_intl.fit()\n",
    "\n",
    "arima_predicted = arima_fit.predict(test.index[0], test.index[-1])\n",
    "arima_predicted_intl = arima_fit_intl.predict(test.index[0], test.index[-1])\n",
    "\n",
    "arima_score_dom = plot_predictions(test['Domestic Passengers'],\n",
    "                                   arima_predicted,\n",
    "                                   'ARIMA model Domestic Passengers JFK',\n",
    "                                   'Domestic Passengers',\n",
    "                                   'arima_jfk_dom_2.svg'\n",
    "                                   )\n",
    "\n",
    "arima_score_intl = plot_predictions(test['Domestic Passengers'],\n",
    "                                    arima_predicted_intl,\n",
    "                                    'ARIMA model International Passengers JFK',\n",
    "                                    'International Passengers',\n",
    "                                    'arima_jfk_intl_2.svg'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951cd55d-1745-48d3-823b-6055c5e492a1",
   "metadata": {},
   "source": [
    "#### Holt-Winters Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b4283-1107-4c90-9e95-e3f3b9e6ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_smoothing(train, test, trend, seasonal, periods, dampening, smooth_slope, damping_slope):\n",
    "    output = {}\n",
    "    exp_smoothing_model = ExponentialSmoothing(train,\n",
    "                                               trend=trend,\n",
    "                                               seasonal=seasonal,\n",
    "                                               seasonal_periods=periods,\n",
    "                                               damped=dampening\n",
    "                                              )\n",
    "    \n",
    "    exp_fit = exp_smoothing_model.fit(smoothing_level=0.9,\n",
    "                                      smoothing_seasonal=0.2,\n",
    "                                      smoothing_slope=smooth_slope,\n",
    "                                      damping_slope=damping_slope,\n",
    "                                      use_brute=True,\n",
    "                                      use_boxcox=False,\n",
    "                                      use_basinhopping=True,\n",
    "                                      remove_bias=True\n",
    "                                     )\n",
    "    forecast = exp_fit.predict(train.index[-1], test.index[-1])\n",
    "    output['model'] = exp_fit\n",
    "    output['forecast'] = forecast[1:]\n",
    "    return output\n",
    "\n",
    "jfk = get_airport_data('JFK', DATA_PATH)\n",
    "jfk = apply_index_freq(jfk, 'MS')\n",
    "train, test = generate_splits(jfk, '2006-07-08')\n",
    "prediction = exp_smoothing(train['Domestic Passengers'], \n",
    "                           test['Domestic Passengers'], \n",
    "                           'add', \n",
    "                           'add', \n",
    "                           48, \n",
    "                           True, \n",
    "                           0.9, \n",
    "                           0.5\n",
    "                          )\n",
    "prediction_intl = exp_smoothing(train['International Passengers'], \n",
    "                                test['International Passengers'], \n",
    "                                'add', \n",
    "                                'add', \n",
    "                                60, \n",
    "                                True, \n",
    "                                0.1, \n",
    "                                1.0\n",
    "                               )\n",
    "exp_smooth_pred = plot_predictions(test['Domestic Passengers'], \n",
    "                                   prediction['forecast'],\n",
    "                                   \"ExponentialSmoothing Domestic Passengers JFK\",\n",
    "                                   \"Domestic Passengers\",\n",
    "                                   \"exp_smooth_dom.svg\"\n",
    "                                  )\n",
    "exp_smooth_pred_intl = plot_predictions(test['International Passengers'], \n",
    "                                   prediction_intl['forecast'],\n",
    "                                   \"ExponentialSmoothing International Passengers JFK\",\n",
    "                                   \"International Passengers\",\n",
    "                                   \"exp_smooth_intl.svg\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fab7d1-3d28-4936-868c-3201f4c685e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af2ec5-0e24-4159-b2c3-0550004fa899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0751e-f2b8-4818-808c-c203a464f547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb90078-4c28-4707-afbf-ddd8278a8504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd2350-f836-47f0-b4a9-16cf40b363cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae152395-8020-47d8-88a2-eebd5a67f961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653e625-862e-4316-a934-0dca0d0afc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77374c78-5b91-415e-b2a1-79d2940bab74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe90d0a-43e6-4821-99de-8f84eb7833ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77e93c-39bb-4569-aad5-9de90812d39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2f24a-3aa1-4583-ba11-ab2820f63281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f576b518-64a9-4bf1-ad79-1db59c1fb781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03252289-eee2-478c-9abc-5fe0d55c2781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e7577-1c86-4503-9512-7df79b055b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
